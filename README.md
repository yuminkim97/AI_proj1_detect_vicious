# AI_proj1_detect_vicious

### 악의적 게시글 판별을 위한 인공지능 모델 생성

0. 사용한 데이터

    https://github.com/ZIZUN/korean-malicious-comments-dataset
    
    해당 데이터 셋은 아래 두 데이터 셋을 가공 후 취합한 것으로, 욕설, 혐오, 비난의 표현이 포함 된 데이터에 대해 0으로, 아닌 경우 1로 라벨링 되어 있다.
    
    https://github.com/kocohub/korean-hate-speech
    
    https://github.com/2runo/Curse-detection-data
    

1. 데이터 전처리
    1) 데이터가 csv.txt 파일로 다운로드 되어 라벨과 contents간 제대로 분리되지 않은 경우가 있어 직접 나눠주었다.
    2) 사용한 데이터의 라벨을 0을 1로, 1을 0으로 바꿔주었다. 즉, 악성댓글 : 1, 일반댓글 : 0으로 라벨링을 새로 하였다.
    3) 정규표현식을 사용하여 댓글 데이터에서 영어 및 특수문자를 제거하고 한글 및 숫자만 포함하였다. 숫자를 남겨둔 이유는 숫자로 욕설을 표현한 경우가 있었기 때문.
    4) 중복 데이터 제거 및 빈 문자열 있는지 확인

      *이후 총 9987개의 댓글 데이터(일반댓글 4996개, 악성댓글 4991개)가 추출됨*

| text | label |
|---|---|
| 이종석 한효주 나오는 드라마 이후로 드라마 안봤다 2년전인가 좀 신선했었지 ... | 1 |
| 씨바알 노무노무 술프노 오늘 저녁은 꽂등심이다ㅠㅜ | 1 |
| 짱깨 꺼라ㅡ패쓰 | 1 |
| 그들의 사생활 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨... | 0 |
| 아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도... | 0 |

2. 토큰화

    Konlpy(코엔엘파이) 패키지의 Okt(Open Korean Text) 형태소 분석기 사용

    불용어는 https://bab2min.tistory.com/544 에서 txt 파일 형태로 다운받아 https://www.ranks.nl/stopwords/korean 을 취합, 적절히 가공하여 총 596개의 불용어 사용

    (ex. 의존 명사로 쓰이는 '씨'의 경우 간혹 욕설로 사용되기 때문에 불용어 사전에서 삭제)

| text | label |
|---|---|
| [이종석, 한효주, 나오는, 드라마, 이후, 드라마, 봤다, 2년, 전인가, 신선했...] | 1 |
| [씨, 바알, 노무, 노무, 술프노, 오늘, 저녁, 꽂, 등심, 이다, ㅠㅜ]	 | 1 |
| [짱깨, 꺼라, ㅡ, 패쓰] | 1 |
| [사생활, 고인, 된, 설리, 위, 해서라도, 모두, 조용하길, 누굴, 탓, 한다고...] | 0 |
| [아무리, 법, 뭣같아, 무슨, 자격, 개인, 신상, 정보, 불, 특정, 다수, 에...] | 0 |


3. 인코딩(Encoding)

    원래 희소단어를 제거하는 과정을 거쳤으나, 댓글 데이터라 문장 자체가 짧아 희소 단어를 제거했을 때 아예 빈 문자열이 되는 경우가 많아짐
    
    따라서 희소 단어 제거 과정은 건너 뜀
    
    토큰에 대해 one-hot encoding 수행 (tensorflow 라이브러리의 Tokenizer().texts_to_sequences 기능 사용)
    
| encoded_text | label |
|---|---|
| [2479, 1817, 554, 75, 779, 75, 1662, 1333, 683...] | 1 |
| [52, 6840, 1334, 1334, 216, 3313, 36, 2480]	 | 1 |
| [329, 294, 6841] | 1 |
| [1518, 537, 141, 175, 153, 509, 1818, 510, 411...] | 0 |
| [404, 412, 71, 1819, 440, 1414, 1091, 842, 402...] | 0 |


4. 패딩(Padding)

    샘플 길이를 맞춰주는 과정
    
    길이가 40이하인 샘플이 약 98.4%. 모든 샘플의 길이를 40으로 맞춰주기로 결정.
    
5. 머신러닝

XGBoost 모델 선정 (총 7개 모델 중 가장 성능이 좋은 것, test_model 디렉토리 내 nlp_test_ml.ipynb 참고)

randomized search CV 사용, best score (accuracy) 0.62

6. 딥러닝

BiLSTM 모델 선정 (총 4개 모델 중 가장 성능이 좋은 것, test_model 디렉토리 내 nlp_test_dl.ipynb 참고)

K Fold CV 사용, best score (accuracy) 0.82

7. 결과

**아래 테스트 데이터에는 다소 자극적인 표현이 포함되어 있습니다.**

| text | label |
|---|---|
| "멍청아ㅋㅋㅋㅋㅋ" | 80.29% 확률로 악의적인 글입니다. |
| '에휴 ㅉㅉ 쓰레ㄱㅣ들아' | 89.34% 확률로 악의적인 글입니다. |
| '씨발' | 89.34% 확률로 악의적인 글입니다. |
| 'ㅆㅣ발' | 88.09% 확률로 악의적인 글입니다. |
| "이런 글이 많았으면 좋겠습니다. 늘 필요하다고 생각했습니다." | 94.80% 확률로 악의적인 글이 아닙니다. |
| '정말 감사합니다' | 84.25% 확률로 악의적인 글이 아닙니다. |
| '아 진짜 너무 귀엽다 ㅠㅠㅠ' | 97.71% 확률로 악의적인 글이 아닙니다. |
| '존나 멋있어' | 94.16% 확률로 악의적인 글입니다. |
| '진짜 못생겼다' | 68.56% 확률로 악의적인 글이 아닙니다. |

위 처럼 욕설을 포함하는 문장의 경우 자음과 모음을 띄워 쓰는 등 약간의 변형이 있어도 모두 욕설이 있음을 판별할 수 있다.

한계 :

욕설을 포함하면 모욕의 의미가 없어도 악의성을 가진 것으로 판단한다.

자극적인 표현이 없고 단순히 문맥으로 그 악의성을 판단해야 하는 경우 판별이 어렵다.
