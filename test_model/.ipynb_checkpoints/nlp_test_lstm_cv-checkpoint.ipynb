{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8989075-d6d5-423d-9825-76c035b9575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "civious_df = pd.read_csv('./data/Dataset.csv.txt', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1cd71f-07a0-4ac0-bc15-e4723be86c96",
   "metadata": {},
   "source": [
    "#### **데이터 전처리**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8be997-cd32-44bb-bf22-99943c5e28ef",
   "metadata": {},
   "source": [
    "1. puntuation 제거 (숫자로 비속어를 표현하는 경우도 있기때문에 숫자는 남겨둠)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c1b9b-fd9d-4617-9fac-a8f5dcc946e7",
   "metadata": {},
   "source": [
    "null 값의 label을 직접 입력해줌\n",
    "\n",
    "하는 김에 label도 int로 바꿔줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a38db4e1-edf0-41a0-9b7c-d6007b376850",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in civious_df[civious_df['lable'].isnull()].index :\n",
    "    textNlabel = civious_df.loc[i, 'content'].split('\\t')\n",
    "    civious_df.loc[i, 'content'] = textNlabel[0]\n",
    "    civious_df.loc[i, 'lable'] = int(textNlabel[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5cf11f9-cf06-4d9f-9cdb-a54e9ac807cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "civious_df['content'] = civious_df['content'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]\",\"\", regex=True)\n",
    "# civious_df['content'] = civious_df['content'].str.replace(\"[:punct:]\",\"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6767ffdf-9d2b-40b0-a35b-dd0ae0dbdce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "civious_df['lable'] = civious_df['lable'].apply(lambda x : int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68d53b2e-a811-45af-ad81-1bb8bd2cd236",
   "metadata": {},
   "outputs": [],
   "source": [
    "civious_df['lable'] = civious_df['lable'].replace([1,0],[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e811b03b-5475-4afe-8754-ec35089c5af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>lable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이종석 한효주 나오는 드라마 이후로 드라마 안봤다 2년전인가 좀 신선했었지 근데 이...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>씨바알노무노무 술프노 오늘 저녁은 꽂등심이다ㅠㅜ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>짱깨 꺼라ㅡ패쓰</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그들의 사생활  고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨소...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  lable\n",
       "0  이종석 한효주 나오는 드라마 이후로 드라마 안봤다 2년전인가 좀 신선했었지 근데 이...      1\n",
       "1                         씨바알노무노무 술프노 오늘 저녁은 꽂등심이다ㅠㅜ      1\n",
       "2                                           짱깨 꺼라ㅡ패쓰      1\n",
       "3  그들의 사생활  고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨소...      0\n",
       "4  아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "civious_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b2317d-6fe5-4222-a851-cf72aae19261",
   "metadata": {},
   "source": [
    "2. 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2eef848-f2a6-4a56-93d8-ff8aaf63aed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content    9982\n",
       "lable         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "civious_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e244443-b692-4c3a-9c1f-d3d04af39dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "civious_df.drop_duplicates(subset=['content'], inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a65f7ad-daab-4891-89ca-4097bdf3bac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9982, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "civious_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3638a-7e33-4b29-a8d1-cf27ad5d451a",
   "metadata": {},
   "source": [
    "3. puntuation 제거 후 빈 문자열이 된 데이터가 있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "873f4bc5-b31e-4f57-af8f-affdc8bab725",
   "metadata": {},
   "outputs": [],
   "source": [
    "civious_df['content'].replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dfa817a-8da0-48ec-8976-319da9371a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9982, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "civious_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d8a3e3c-bc87-4734-a194-ecd03771a3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content    0\n",
      "lable      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(civious_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb0b43e-c655-486c-8293-6ce4b4d801ca",
   "metadata": {},
   "source": [
    "content column에 빈 문자열은 없음!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846dd4e2-0043-4004-9c2e-5129c63ebe61",
   "metadata": {},
   "source": [
    "#### **토큰화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32540e8b-95dc-4e18-8b3c-b871fae60d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "\n",
    "#stopwords text file 중 '씨, 문제' 제거\n",
    "stopwords_file = open('./data/korean_stopwords.txt', 'r', encoding='UTF8')\n",
    "stopwords_lines = stopwords_file.readlines()\n",
    "for line in stopwords_lines :\n",
    "    stopwords.append(line.split('\\t')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09ed8376-b64e-4fff-b0df-5e4c57c0245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jpype #이거 안쓰면 에러남!!!!\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "token_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdc68cf4-d5a2-4085-8492-72dc6adc7018",
   "metadata": {},
   "outputs": [],
   "source": [
    "toknized_df = pd.DataFrame(columns=['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992bec0c-7cd3-4539-97e3-04ccfc83d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in civious_df.index :\n",
    "    sentence = civious_df.loc[i, 'content']\n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    toknized_df.loc[i, 'text'] = temp_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0db059-0daa-4d44-a94c-05900dc59fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "toknized_df['label'] = civious_df['lable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56adb2da-75d8-4d74-8220-8d58a89bb649",
   "metadata": {},
   "outputs": [],
   "source": [
    "toknized_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a64277-ad22-490a-aad0-0cca1d1645b1",
   "metadata": {},
   "source": [
    "#### **인코딩**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8b800b-f2b1-40be-b754-bab3bf8b9fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(toknized_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09601e85-5166-446d-9a91-63a327843db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if (value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f5713b-7dde-45b5-9c61-115351a286db",
   "metadata": {},
   "source": [
    "3회 미만으로 등장하는 단어가 8.9퍼센트를 차지한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba3ed8f-f7bf-4437-b4c7-6075dadbe243",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = total_cnt - rare_cnt + 1\n",
    "print('단어 집합의 크기 :',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb023838-90fc-4e90-a5db-d70e8b512146",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size) \n",
    "tokenizer.fit_on_texts(toknized_df['text'])\n",
    "toknized_df['encoding'] = tokenizer.texts_to_sequences(toknized_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d755c734-b049-46ae-b521-821281915b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "toknized_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971e10bc-a4bd-48e7-8604-6ede858c8c96",
   "metadata": {},
   "source": [
    "문장을 구성하는 모든 단어가 희귀 단어여서 빈 encoding sequence를 생성하는 경우를 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b5131b-d658-4d1c-a39e-ef9ea63ac6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_index = [index for index, sentence in enumerate(toknized_df['encoding']) if len(sentence) < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87b1ac-87c4-4029-8a1a-fad2534df3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(drop_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd1968-ddfb-496b-8b49-a6c06b657602",
   "metadata": {},
   "outputs": [],
   "source": [
    "toknized_df.drop(index=drop_index, axis=0, inplace=True)\n",
    "# toknized_df = np.delete(toknized_df, drop_index, axis=0)\n",
    "toknized_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2436460e-08e4-408a-8ac3-b4a0cfc56a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "toknized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23b2337-de6b-475f-b4ca-0c8fed27d75c",
   "metadata": {},
   "source": [
    "#### **패딩**\n",
    "샘플 길이 맞춰주는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d588ae8f-442d-4734-9a7b-ea5e24996e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('시퀀스 최대 길이 :',max(len(l) for l in toknized_df['encoding']))\n",
    "print('시퀀스 평균 길이 :',sum(map(len, toknized_df['encoding']))/len(toknized_df['encoding']))\n",
    "plt.hist([len(s) for s in toknized_df['encoding']], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110a074a-8f78-4d28-af1e-a73603b1ea60",
   "metadata": {},
   "source": [
    "최적의 시퀀스 길이(대부분의 텍스트가 내용이 잘리지 않도록 할 수 있는 최적의 max_len의 값)는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3329ee7b-8a24-4ffd-899b-6e042e42a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b944e5a4-0449-45a2-b6aa-b20a42b873a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 40\n",
    "below_threshold_len(max_len, toknized_df['encoding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2e93b1-99a8-4ce9-8ed2-db52c8ca80a3",
   "metadata": {},
   "source": [
    "전체 데이터 중 약 97%의 샘플이 40 이하의 길이를 가짐. 모든 시퀀스 길이를 40으로 맞추기로 결정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6207ac21-7524-4de1-8a87-65863b06ffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "encoded_text = pad_sequences(toknized_df['encoding'], maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258870f9-8e1b-4c4d-af9c-41d61ea58e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = pd.DataFrame(data=encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba04ff4-83a7-440c-aaf4-bb1e0ee6b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(encoded_df, toknized_df['label'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17812429-0fa2-41c0-9f6c-84df08bc3f61",
   "metadata": {},
   "source": [
    "### **Deep learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e6fa48-c41d-41aa-a235-413853ffaf6a",
   "metadata": {},
   "source": [
    "2. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a212e9-8d8e-428f-8c64-0bbe27d1a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ab5fb-415c-4c57-93dd-5aceb408edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "# fix random seed for reproducibility \n",
    "seed = 7 \n",
    "np.random.seed(seed)\n",
    "\n",
    "def create_model(dropout_rate=0.01):\n",
    "#     lstm_model = Sequential()\n",
    "#     lstm_model.add(Embedding(vocab_size, 100))\n",
    "#     lstm_model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "#     lstm_model.add(Dropout(dropout_rate))\n",
    "#     lstm_model.add(Bidirectional(LSTM(25, return_sequences=True)))\n",
    "#     lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(Embedding(vocab_size, 100))\n",
    "    lstm_model.add(LSTM(128))\n",
    "    lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "    lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return lstm_model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=100, verbose=0)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "results = cross_val_score(model, X_train, y_train, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21dacdf-9dfe-42e1-b78f-bdc72f554dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddd4734-0af8-43db-9dd5-8d41d977104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def create_model():\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(Embedding(vocab_size, 100))\n",
    "    lstm_model.add(LSTM(128))\n",
    "    lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "    lstm_model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return lstm_model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "batch_size = [50, 100, 300]\n",
    "epochs = [10, 20, 30]\n",
    "optimizer = ['Nadam', 'Adam', 'RMSProp']\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "93651007-0388-4a72-a1a6-bfe497fe3e57",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'it' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-35c87270cf67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0meval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcombination\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mrun_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-65-35c87270cf67>\u001b[0m in \u001b[0;36mrun_search\u001b[1;34m(mat, params)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mparam_combs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_all_combinations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# list of tuples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Total combinations to try = {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_combs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcombination\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_combs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-35c87270cf67>\u001b[0m in \u001b[0;36mget_all_combinations\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_all_combinations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mall_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mcombinations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'it' is not defined"
     ]
    }
   ],
   "source": [
    "search_params = {\n",
    "    \"batch_size\": [20, 30, 40],\n",
    "    \"time_steps\": [30, 60, 90], \n",
    "    \"lr\": [0.01, 0.001, 0.0001],\n",
    "    \"epochs\": [30, 50, 70]\n",
    "}\n",
    "\n",
    "def eval_model():\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(Embedding(vocab_size, 100))\n",
    "    lstm_model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "    lstm_model.add(Dropout(dropout_rate))\n",
    "    lstm_model.add(Bidirectional(LSTM(25, return_sequences=True)))\n",
    "    lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "    return lstm_model\n",
    "\n",
    "def get_all_combinations(params):\n",
    "    all_names = params.keys()\n",
    "    combinations = it.product(*(params[name] for name in all_names))\n",
    "    return list(combinations)\n",
    "\n",
    "def run_search(mat, params):\n",
    "    param_combs = get_all_combinations(params) # list of tuples\n",
    "    logging.info(\"Total combinations to try = {}\".format(len(param_combs)))\n",
    "    for i, combination in enumerate(param_combs):\n",
    "        logging.info(\"Trying combo no. {} {}\".format(i, combination))\n",
    "        eval_model(mat, combination, i)\n",
    "\n",
    "run_search(X_train, search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0f743385-565d-40dd-b1c0-2e311f4e3177",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\n",
    "    'batch_size': [348,256,200,128],\n",
    "    'lstm1_nodes': list(range(70, 150, 10)),\n",
    "    'lstm1_dropouts': [0.1,0.2,0.4,0.6],\n",
    "    'learning_rate': [0.001,0.01,0.1,0.0001],\n",
    "    \"epochs\": list(range(30, 50, 10)),\n",
    "    \"optimizer\": ['Nadam', 'Adam', 'RMSProp'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d4c2532-8364-4878-a38e-884d3df4d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param_LSTM = {\n",
    "    'batch_size': [348,256,200,128],\n",
    "    'epochs': [15,30],   \n",
    "    'learning_rate':[0.001,0.01,0.1,0.0001],\n",
    "    'optimizer': ['Nadam', 'Adam', 'RMSProp'],\n",
    "    'loss': ['logcosh', 'mae', 'mse', 'hinge','squared_hinge'],\n",
    "    'activation': ['relu', 'linear','sigmoid','hard_sigmoid', 'tanh'],\n",
    "    'dropout_rate':[0.1,0.2,0.4,0.6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93e2216d-a649-484d-b790-663a1a0a7f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(vocab_size, 100))\n",
    "lstm_model.add(LSTM(128))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c217d62d-eb49-4389-af8a-cd5dfeaa5cf2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "learning_rate is not a legal parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"c:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"c:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 586, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"c:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 127, in set_params\n    self.check_params(params)\n  File \"c:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 103, in check_params\n    raise ValueError('{} is not a legal parameter'.format(params_name))\nValueError: learning_rate is not a legal parameter\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-a7db258b73be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mKmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrid_param_LSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'boolean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: learning_rate is not a legal parameter"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "\n",
    "def getModel(optimizer):\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(Embedding(vocab_size, 100))\n",
    "    lstm_model.add(LSTM(128))\n",
    "    lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "    return lstm_model\n",
    "\n",
    "grid_param_LSTM = {\n",
    "    'batch_size': [348,256,200,128],\n",
    "    'epochs': [15,30],   \n",
    "    'learning_rate':[0.001,0.01,0.1,0.0001],\n",
    "    'optimizer': ['Nadam', 'Adam', 'RMSProp'],\n",
    "    'loss': ['logcosh', 'mae', 'mse', 'hinge','squared_hinge'],\n",
    "}\n",
    "\n",
    "Kmodel = KerasClassifier(build_fn=getModel, verbose=1)\n",
    "grid = GridSearchCV(estimator=Kmodel, param_grid=grid_param_LSTM, scoring='accuracy', n_jobs=-1, refit='boolean')\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fe64bd8e-d7b4-48f2-8b71-062ed9a998ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002201888FB20>' (type <class 'tensorflow.python.keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-e2a67d8837e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv_orig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m         \u001b[0mbase_estimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m         parallel = Parallel(n_jobs=self.n_jobs,\n",
      "\u001b[1;32mc:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     65\u001b[0m                                 \"scikit-learn estimator instead of a class.\")\n\u001b[0;32m     66\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                 raise TypeError(\"Cannot clone object '%s' (type %s): \"\n\u001b[0m\u001b[0;32m     68\u001b[0m                                 \u001b[1;34m\"it does not seem to be a scikit-learn \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                                 \u001b[1;34m\"estimator as it does not implement a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot clone object '<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002201888FB20>' (type <class 'tensorflow.python.keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=lstm_model, param_grid=param_grid, n_jobs=-1, scoring=\"accuracy\")\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cc73d58f-0f63-4fa3-aa83-d2ab73feb4be",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002201888FB20>' (type <class 'tensorflow.python.keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-bbf9d4c13cd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         scoring=\"accuracy\")\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mrf_random_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv_orig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m         \u001b[0mbase_estimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m         parallel = Parallel(n_jobs=self.n_jobs,\n",
      "\u001b[1;32mc:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yumin\\anaconda3\\envs\\proj1_vic\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     65\u001b[0m                                 \"scikit-learn estimator instead of a class.\")\n\u001b[0;32m     66\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                 raise TypeError(\"Cannot clone object '%s' (type %s): \"\n\u001b[0m\u001b[0;32m     68\u001b[0m                                 \u001b[1;34m\"it does not seem to be a scikit-learn \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                                 \u001b[1;34m\"estimator as it does not implement a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot clone object '<tensorflow.python.keras.engine.sequential.Sequential object at 0x000002201888FB20>' (type <class 'tensorflow.python.keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "        estimator=lstm_model,\n",
    "        param_distributions = grid_param_LSTM,\n",
    "        n_iter = 20,\n",
    "        cv = 5,\n",
    "        scoring=\"accuracy\")\n",
    "\n",
    "rf_random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e2a5445-434c-40e3-9a2f-a89813da8e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc_lstm = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36a765c4-99da-456e-a1d8-035c3eb4a88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "100/100 [==============================] - 10s 68ms/step - loss: 0.5628 - acc: 0.6960 - val_loss: 0.4388 - val_acc: 0.7926\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.79264, saving model to best_model.h5\n",
      "Epoch 2/15\n",
      "100/100 [==============================] - 6s 60ms/step - loss: 0.3438 - acc: 0.8508 - val_loss: 0.4084 - val_acc: 0.8161\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.79264 to 0.81605, saving model to best_model.h5\n",
      "Epoch 3/15\n",
      "100/100 [==============================] - 7s 66ms/step - loss: 0.2573 - acc: 0.8978 - val_loss: 0.4133 - val_acc: 0.8308\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.81605 to 0.83077, saving model to best_model.h5\n",
      "Epoch 4/15\n",
      "100/100 [==============================] - 6s 63ms/step - loss: 0.2050 - acc: 0.9192 - val_loss: 0.4259 - val_acc: 0.8281\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.83077\n",
      "Epoch 5/15\n",
      "100/100 [==============================] - 7s 73ms/step - loss: 0.1739 - acc: 0.9318 - val_loss: 0.4467 - val_acc: 0.8054\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.83077\n",
      "Epoch 6/15\n",
      "100/100 [==============================] - 7s 68ms/step - loss: 0.1499 - acc: 0.9430 - val_loss: 0.4988 - val_acc: 0.8201\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.83077\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "lstm_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "lstm_history = lstm_model.fit(X_train, y_train, epochs=15, callbacks=[es, mc_lstm], batch_size=60, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45dbc264-ed04-4e16-bc37-fc3a296d4f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 2s 17ms/step - loss: 0.3892 - acc: 0.8419\n",
      "\n",
      " 테스트 정확도: 0.8419\n"
     ]
    }
   ],
   "source": [
    "lstm_loaded_model = load_model('best_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (lstm_loaded_model.evaluate(X_valid, y_valid)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f355835-1626-49d2-b2c8-9a8bd7d4e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(new_sentence):\n",
    "    new_sentence = okt.morphs(new_sentence, stem=True) # 토큰화\n",
    "    new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
    "    encoded = tokenizer.texts_to_sequences([new_sentence]) # 정수 인코딩\n",
    "    pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩\n",
    "    return pad_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1099dab-84ce-44ed-8413-16671d328024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_predict(new_sentence):\n",
    "  processed_text = preprocess_text(new_sentence)\n",
    "  score = float(lstm_loaded_model.predict(processed_text)) # 예측\n",
    "  if(score > 0.5):\n",
    "    print(\"{:.2f}% 확률로 악의적인 글입니다.\\n\".format(score * 100))\n",
    "  else:\n",
    "    print(\"{:.2f}% 확률로 악의적인 글이 아닙니다.\\n\".format((1 - score) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cde8b35e-e15c-48de-8519-f66501c89c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.76% 확률로 악의적인 글이 아닙니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_predict('못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "66e29bf0-f1b2-4962-ae5a-c8a84bc0e33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.97% 확률로 악의적인 글입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_predict(\"개소리야 니가 빨갱이를 옹호하고 드루킹을 ㅇㅇ짓이라고 말못해서 삐진거야 빨갱아\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fcbbf3b9-5200-473a-b82c-25291a23bcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.37% 확률로 악의적인 글이 아닙니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_predict('이 영화 핵노잼 ㅠㅠ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "570ce89f-dce7-40de-99aa-9a60f45d8e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.05% 확률로 악의적인 글입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_predict('이딴게 영화냐 ㅉㅉ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb26f449-a337-47e4-b8d9-4c7f28ba8f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
